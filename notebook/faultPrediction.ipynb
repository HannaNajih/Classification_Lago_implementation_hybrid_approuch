{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a03726c",
   "metadata": {},
   "source": [
    "## Software Fault Prediction using Classification algorithms\n",
    "\n",
    "### we used pc1 file to do tasks, because we have the results in the paper that has been taken on this dataset\n",
    "\n",
    "**if you want to get results with other files you can just simply load the dataset name instead of pc1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4bdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec696da",
   "metadata": {},
   "source": [
    "### First of all, we will inport and define the important libraries, we should run this bloch of code before running the rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Dataset\n",
    "\n",
    "data = pd.read_csv('../data/pc1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed6e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loc  v(g)  ev(g)  iv(g)     n       v     l      d      i        e  ...  \\\n",
      "0   1.1   1.4    1.4    1.4   1.3    1.30  1.30   1.30   1.30     1.30  ...   \n",
      "1   1.0   1.0    1.0    1.0   1.0    1.00  1.00   1.00   1.00     1.00  ...   \n",
      "2  24.0   5.0    1.0    3.0  63.0  309.13  0.11   9.50  32.54  2936.77  ...   \n",
      "3  20.0   4.0    4.0    2.0  47.0  215.49  0.06  16.00  13.47  3447.89  ...   \n",
      "4  24.0   6.0    6.0    2.0  72.0  346.13  0.06  17.33  19.97  5999.58  ...   \n",
      "\n",
      "   lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
      "0       2          2        2                  2      1.2        1.2   \n",
      "1       1          1        1                  1      1.0        1.0   \n",
      "2       1          0        6                  0     15.0       15.0   \n",
      "3       0          0        3                  0     16.0        8.0   \n",
      "4       0          0        3                  0     16.0       12.0   \n",
      "\n",
      "   total_Op  total_Opnd  branchCount  defects  \n",
      "0       1.2         1.2          1.4    False  \n",
      "1       1.0         1.0          1.0     True  \n",
      "2      44.0        19.0          9.0    False  \n",
      "3      31.0        16.0          7.0    False  \n",
      "4      46.0        26.0         11.0    False  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 498 entries, 0 to 497\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   loc                498 non-null    float64\n",
      " 1   v(g)               498 non-null    float64\n",
      " 2   ev(g)              498 non-null    float64\n",
      " 3   iv(g)              498 non-null    float64\n",
      " 4   n                  498 non-null    float64\n",
      " 5   v                  498 non-null    float64\n",
      " 6   l                  498 non-null    float64\n",
      " 7   d                  498 non-null    float64\n",
      " 8   i                  498 non-null    float64\n",
      " 9   e                  498 non-null    float64\n",
      " 10  b                  498 non-null    float64\n",
      " 11  t                  498 non-null    float64\n",
      " 12  lOCode             498 non-null    int64  \n",
      " 13  lOComment          498 non-null    int64  \n",
      " 14  lOBlank            498 non-null    int64  \n",
      " 15  locCodeAndComment  498 non-null    int64  \n",
      " 16  uniq_Op            498 non-null    float64\n",
      " 17  uniq_Opnd          498 non-null    float64\n",
      " 18  total_Op           498 non-null    float64\n",
      " 19  total_Opnd         498 non-null    float64\n",
      " 20  branchCount        498 non-null    float64\n",
      " 21  defects            498 non-null    bool   \n",
      "dtypes: bool(1), float64(17), int64(4)\n",
      "memory usage: 82.3 KB\n",
      "None\n",
      "              loc        v(g)       ev(g)       iv(g)            n  \\\n",
      "count  498.000000  498.000000  498.000000  498.000000   498.000000   \n",
      "mean    29.644779    5.382329    2.490763    3.528916   143.956426   \n",
      "std     42.753572    8.347359    3.658847    5.464398   221.049888   \n",
      "min      1.000000    1.000000    1.000000    1.000000     1.000000   \n",
      "25%      8.000000    1.000000    1.000000    1.000000    25.000000   \n",
      "50%     17.000000    3.000000    1.000000    2.000000    67.500000   \n",
      "75%     31.000000    6.000000    1.000000    4.000000   151.750000   \n",
      "max    423.000000   96.000000   30.000000   63.000000  2075.000000   \n",
      "\n",
      "                  v           l           d           i             e  ...  \\\n",
      "count    498.000000  498.000000  498.000000  498.000000  4.980000e+02  ...   \n",
      "mean     900.175823    0.146325   15.829378   38.455361  3.488493e+04  ...   \n",
      "std     1690.814334    0.159337   15.330960   36.996297  1.341647e+05  ...   \n",
      "min        0.000000    0.000000    0.000000    0.000000  0.000000e+00  ...   \n",
      "25%      102.190000    0.050000    5.630000   16.210000  6.061700e+02  ...   \n",
      "50%      329.820000    0.090000   11.640000   27.400000  3.677620e+03  ...   \n",
      "75%      861.460000    0.177500   21.142500   46.900000  1.663334e+04  ...   \n",
      "max    17124.280000    1.300000  125.770000  293.680000  2.153691e+06  ...   \n",
      "\n",
      "                   t      lOCode   lOComment     lOBlank  locCodeAndComment  \\\n",
      "count     498.000000  498.000000  498.000000  498.000000         498.000000   \n",
      "mean     1938.056124    3.787149   12.283133   11.534137           0.006024   \n",
      "std      7453.591519    8.508658   25.828605   19.981476           0.100120   \n",
      "min         0.000000    0.000000    0.000000    0.000000           0.000000   \n",
      "25%        33.672500    0.000000    0.000000    1.000000           0.000000   \n",
      "50%       204.310000    1.000000    4.000000    5.000000           0.000000   \n",
      "75%       924.075000    4.000000   14.000000   13.000000           0.000000   \n",
      "max    119649.480000   80.000000  339.000000  164.000000           2.000000   \n",
      "\n",
      "          uniq_Op   uniq_Opnd     total_Op  total_Opnd  branchCount  \n",
      "count  498.000000  498.000000   498.000000  498.000000   498.000000  \n",
      "mean    15.199197   25.452209    88.389960   55.570683     9.348193  \n",
      "std      9.617815   33.925816   134.917513   86.969527    15.072219  \n",
      "min      1.000000    0.000000     1.000000    0.000000     1.000000  \n",
      "25%      9.000000    7.000000    15.000000   10.000000     1.000000  \n",
      "50%     14.000000   15.000000    42.000000   26.000000     5.000000  \n",
      "75%     20.000000   30.000000    94.750000   59.750000    11.000000  \n",
      "max     72.000000  314.000000  1261.000000  814.000000   162.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2. Explore the dataset (optional)\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf80133",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### we have Explored the dataset just to see and understand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e933577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocessing\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # or 'median' depending on your data\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94bcd0",
   "metadata": {},
   "source": [
    "### Here, we will handle missing values if exists in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1858182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data_imputed.drop('defects', axis=1)  \n",
    "y = data_imputed['defects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b944863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical target if necessary\n",
    "if y.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ded45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (important for KNN and SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5eaaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define classifiers\n",
    "classifiers = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe2a75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8896\n",
      "Precision: 0.0500\n",
      "Recall: 0.0200\n",
      "F1-score: 0.0286\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluation using 10-fold cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_scaled, y):\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred, zero_division=0))\n",
    "    f1s.append(f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(f\"Accuracy: {np.mean(accuracies):.4f}\")\n",
    "print(f\"Precision: {np.mean(precisions):.4f}\")\n",
    "print(f\"Recall: {np.mean(recalls):.4f}\")\n",
    "print(f\"F1-score: {np.mean(f1s):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72efaa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d106d920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision  Recall  F1-score\n",
      "Decision Tree           0.851551   0.265952   0.205  0.207172\n",
      "K-Nearest Neighbors     0.887592   0.200000   0.040  0.066667\n",
      "Support Vector Machine  0.899633   0.000000   0.000  0.000000\n",
      "Random Forest           0.889633   0.050000   0.020  0.028571\n"
     ]
    }
   ],
   "source": [
    "# 6. Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbe52f",
   "metadata": {},
   "source": [
    "# 7. Compare your results with the paper's reported results\n",
    "# (Manually add the paper's results here for comparison in my report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d53ebb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Your Results vs Paper's Reported Results (PC1 Dataset):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy_Your</th>\n",
       "      <th>Precision_Your</th>\n",
       "      <th>Recall_Your</th>\n",
       "      <th>F1-score_Your</th>\n",
       "      <th>Accuracy_Paper</th>\n",
       "      <th>Precision_Paper</th>\n",
       "      <th>Recall_Paper</th>\n",
       "      <th>F1-score_Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.851551</td>\n",
       "      <td>0.265952</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.207172</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>0.887592</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.899633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.889633</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier  Accuracy_Your  Precision_Your  Recall_Your  \\\n",
       "0           Decision Tree       0.851551        0.265952        0.205   \n",
       "1      K-Nearest Neighbor       0.887592        0.200000        0.040   \n",
       "2  Support Vector Machine       0.899633        0.000000        0.000   \n",
       "3           Random Forest       0.889633        0.050000        0.020   \n",
       "\n",
       "   F1-score_Your  Accuracy_Paper  Precision_Paper  Recall_Paper  \\\n",
       "0       0.207172           0.912            0.583         0.512   \n",
       "1       0.066667           0.923            0.615         0.564   \n",
       "2       0.000000           0.924            0.635         0.573   \n",
       "3       0.028571           0.930            0.653         0.598   \n",
       "\n",
       "   F1-score_Paper  \n",
       "0           0.545  \n",
       "1           0.588  \n",
       "2           0.602  \n",
       "3           0.624  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# My results \n",
    "my_results = {\n",
    "    'Classifier': ['Decision Tree', 'K-Nearest Neighbor', 'Support Vector Machine', 'Random Forest'],\n",
    "    'Accuracy_Your': [0.851551, 0.887592, 0.899633, 0.889633],\n",
    "    'Precision_Your': [0.265952, 0.200000, 0.000000, 0.050000],\n",
    "    'Recall_Your': [0.205, 0.040, 0.000, 0.020],\n",
    "    'F1-score_Your': [0.207172, 0.066667, 0.000000, 0.028571]\n",
    "}\n",
    "\n",
    "# Paper's reported results for PC1 dataset (from Table 2 in the paper)\n",
    "paper_results = {\n",
    "    'Classifier': ['Decision Tree', 'K-Nearest Neighbor', 'Support Vector Machine', 'Random Forest'],\n",
    "    'Accuracy_Paper': [0.912, 0.923, 0.924, 0.930],\n",
    "    'Precision_Paper': [0.583, 0.615, 0.635, 0.653],\n",
    "    'Recall_Paper': [0.512, 0.564, 0.573, 0.598],\n",
    "    'F1-score_Paper': [0.545, 0.588, 0.602, 0.624]\n",
    "}\n",
    "\n",
    "# Create DataFrames\n",
    "df_your = pd.DataFrame(my_results)\n",
    "df_paper = pd.DataFrame(paper_results)\n",
    "\n",
    "# Merge on Classifier\n",
    "comparison_df = pd.merge(df_your, df_paper, on='Classifier')\n",
    "\n",
    "# Display the comparison table\n",
    "print(\"Comparison of Your Results vs Paper's Reported Results (PC1 Dataset):\")\n",
    "display(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda1e0f",
   "metadata": {},
   "source": [
    "### Comparison of Our Results with the Paper’s Reported Results\n",
    "\n",
    "The table below presents a side-by-side comparison of the performance metrics obtained from our implementation of classical classifiers on the PC1 dataset with the results reported in the paper *“A hybrid approach based on k-nearest neighbors and decision tree for software fault prediction.”*\n",
    "\n",
    "| Classifier           | Accuracy (Our) | Accuracy (Paper) | Precision (Our) | Precision (Paper) | Recall (Our) | Recall (Paper) | F1-score (Our) | F1-score (Paper) |\n",
    "|----------------------|----------------|------------------|-----------------|-------------------|--------------|----------------|----------------|------------------|\n",
    "| Decision Tree        | 0.852          | 0.912            | 0.266           | 0.583             | 0.205        | 0.512          | 0.207          | 0.545            |\n",
    "| K-Nearest Neighbor   | 0.888          | 0.923            | 0.200           | 0.615             | 0.040        | 0.564          | 0.067          | 0.588            |\n",
    "| Support Vector Machine | 0.900        | 0.924            | 0.000           | 0.635             | 0.000        | 0.573          | 0.000          | 0.602            |\n",
    "| Random Forest        | 0.890          | 0.930            | 0.050           | 0.653             | 0.020        | 0.598          | 0.029          | 0.624            |\n",
    "\n",
    "#### Analysis:\n",
    "\n",
    "- Our accuracy scores are reasonably close to those reported in the paper, indicating that the classifiers are generally effective at correctly classifying the majority class.\n",
    "- However, our precision, recall, and F1-scores are significantly lower, especially for SVM and Random Forest, which suggests that our models struggle to correctly identify the minority (faulty) class.\n",
    "- This discrepancy may be due to class imbalance in the dataset, differences in preprocessing steps, parameter tuning, or the use of additional techniques such as class weighting or resampling in the paper.\n",
    "- To improve minority class detection, future work could involve applying class balancing methods (e.g., SMOTE), hyperparameter tuning, or implementing the hybrid approach proposed in the paper.\n",
    "- Overall, our results validate the baseline performance of classical classifiers and highlight the potential benefits of the hybrid model for software fault prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save results to CSV \n",
    "results_df.to_csv('classification_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0026d",
   "metadata": {},
   "source": [
    "*this is my results i saved them in the csv file* \n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
